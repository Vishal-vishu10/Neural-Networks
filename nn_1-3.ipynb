{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_WmNSWU1Cg7m"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "The main code for the recurrent and convolutional networks assignment.\n",
        "See README.md for details.\n",
        "\"\"\"\n",
        "from typing import Tuple, List, Dict\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Conv2D, MaxPool2D, Flatten, Embedding, Conv1D, GlobalMaxPool1D, Dropout, BatchNormalization, TimeDistributed\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def create_toy_rnn(input_shape: tuple, n_outputs: int) \\\n",
        "        -> Tuple[tensorflow.keras.models.Model, Dict]:\n",
        "    \"\"\"Creates a recurrent neural network for a toy problem.\"\"\"\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(64, return_sequences=True),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "        LSTM(32, return_sequences=True),\n",
        "        BatchNormalization(),\n",
        "        TimeDistributed(Dense(16, activation='relu')),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "        Dense(n_outputs, activation='linear')\n",
        "    ])\n",
        "\n",
        "    optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.015, weight_decay=0.005)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                 loss='mse',\n",
        "                 metrics=['mae'])\n",
        "\n",
        "    fit_kwargs = {\n",
        "        'batch_size': 1,\n",
        "        'callbacks': [EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
        "    }\n",
        "\n",
        "    return model, fit_kwargs\n",
        "\n",
        "def create_mnist_cnn(input_shape: tuple, n_outputs: int) \\\n",
        "        -> Tuple[tensorflow.keras.models.Model, Dict]:\n",
        "    \"\"\"Creates a convolutional neural network for digit classification.\"\"\"\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPool2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPool2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(n_outputs, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    fit_kwargs = {\n",
        "        'batch_size': 32,\n",
        "        'callbacks': [EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
        "    }\n",
        "\n",
        "    return model, fit_kwargs\n",
        "\n",
        "def create_youtube_comment_rnn(vocabulary: List[str], n_outputs: int) \\\n",
        "        -> Tuple[tensorflow.keras.models.Model, Dict]:\n",
        "    \"\"\"Creates a recurrent neural network for spam classification.\"\"\"\n",
        "    vocab_size = len(vocabulary)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape=(None,)),\n",
        "        Embedding(input_dim=vocab_size, output_dim=64, mask_zero=True),  # Restored to 64\n",
        "        LSTM(64, return_sequences=False),  # Restored to 64\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),  # Restored to 32\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),  # Added second dropout\n",
        "        Dense(n_outputs, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.001, weight_decay=0.01)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                 loss='binary_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    fit_kwargs = {\n",
        "        'batch_size': 32,\n",
        "        'callbacks': [EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]  # Reduced patience\n",
        "    }\n",
        "\n",
        "    return model, fit_kwargs\n",
        "\n",
        "def create_youtube_comment_cnn(vocabulary: List[str], n_outputs: int) \\\n",
        "        -> Tuple[tensorflow.keras.models.Model, Dict]:\n",
        "    \"\"\"Creates a convolutional neural network for spam classification.\"\"\"\n",
        "    vocab_size = len(vocabulary)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape=(None,)),\n",
        "        Embedding(input_dim=vocab_size, output_dim=32),\n",
        "        Conv1D(64, 5, activation='relu'),\n",
        "        GlobalMaxPool1D(),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(n_outputs, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='binary_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    fit_kwargs = {\n",
        "        'batch_size': 32,\n",
        "        'callbacks': [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "    }\n",
        "\n",
        "    return model, fit_kwargs"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PKr-JCxSUId_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}